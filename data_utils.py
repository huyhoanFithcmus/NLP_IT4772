import re
import numpy as np
from tqdm import tqdm
from load_data import word2idx 

strip_special_chars = re.compile("[^\w0-9 ]+")
replace_list={'Ã²a':'oÃ ','Ã³a':'oÃ¡','á»a':'oáº£','Ãµa':'oÃ£','á»a':'oáº¡','Ã²e':'oÃ¨','Ã³e':'oÃ©','á»e':'oáº»','Ãµe':'oáº½','á»e':'oáº¹','Ã¹y':'uá»³','Ãºy':'uÃ½','á»§y':'uá»·','Å©y':'uá»¹','á»¥y':'uá»µ','uáº£':'á»§a','aÌ‰':'áº£','Ã´Ì':'á»‘','uÂ´':'á»‘','Ã´Ìƒ':'á»—','Ã´Ì€':'á»“','Ã´Ì‰':'á»•','Ã¢Ì':'áº¥','Ã¢Ìƒ':'áº«','Ã¢Ì‰':'áº©','Ã¢Ì€':'áº§','oÌ‰':'á»','ÃªÌ€':'á»','ÃªÌƒ':'á»…','ÄƒÌ':'áº¯','uÌ‰':'á»§','ÃªÌ':'áº¿','Æ¡Ì‰':'á»Ÿ','iÌ‰':'á»‰','eÌ‰':'áº»','Ã k':' Ã  ','aË‹':'Ã ','iË‹':'Ã¬','ÄƒÂ´':'áº¯','Æ°Ì‰':'á»­','eËœ':'áº½','yËœ':'á»¹','aÂ´':'Ã¡','ğŸ‘¹':'tiÃªu cá»±c','ğŸ‘»':'tÃ­ch cá»±c','ğŸ’ƒ':'tÃ­ch cá»±c','ğŸ¤™':'tÃ­ch cá»±c','ğŸ‘':'tÃ­ch cá»±c','ğŸ’„':'tÃ­ch cá»±c','ğŸ’':'tÃ­ch cá»±c','ğŸ’©':'tÃ­ch cá»±c','ğŸ˜•':'tiÃªu cá»±c','ğŸ˜±':'tiÃªu cá»±c','ğŸ˜¸':'tÃ­ch cá»±c','ğŸ˜¾':'tiÃªu cá»±c','ğŸš«':'tiÃªu cá»±c','\U0001f92c':'tiÃªu cá»±c','\U0001f9da':'tÃ­ch cá»±c','\U0001f9e1':'tÃ­ch cá»±c','ğŸ¶':'tÃ­ch cá»±c','ğŸ‘':'tiÃªu cá»±c','ğŸ˜£':'tiÃªu cá»±c','âœ¨':'tÃ­ch cá»±c','â£':'tÃ­ch cá»±c','â˜€':'tÃ­ch cá»±c','â™¥':'tÃ­ch cá»±c','\U0001f929':'tÃ­ch cá»±c','like':'tÃ­ch cá»±c','ğŸ’Œ':'tÃ­ch cá»±c','ğŸ¤£':'tÃ­ch cá»±c','ğŸ–¤':'tÃ­ch cá»±c','ğŸ¤¤':'tÃ­ch cá»±c',':(':'tiÃªu cá»±c','ğŸ˜¢':'tiÃªu cá»±c','â¤':'tÃ­ch cá»±c','ğŸ˜':'tÃ­ch cá»±c','ğŸ˜˜':'tÃ­ch cá»±c','ğŸ˜ª':'tiÃªu cá»±c','ğŸ˜Š':'tÃ­ch cá»±c','?':' ? ','ğŸ˜':'tÃ­ch cá»±c','ğŸ’–':'tÃ­ch cá»±c','ğŸ˜Ÿ':'tiÃªu cá»±c','ğŸ˜­':'tiÃªu cá»±c','ğŸ’¯':'tÃ­ch cá»±c','ğŸ’—':'tÃ­ch cá»±c','â™¡':'tÃ­ch cá»±c','ğŸ’œ':'tÃ­ch cá»±c','ğŸ¤—':'tÃ­ch cá»±c','^^':'tÃ­ch cá»±c','ğŸ˜¨':'tiÃªu cá»±c','â˜º':'tÃ­ch cá»±c','ğŸ’‹':'tÃ­ch cá»±c','ğŸ‘Œ':'tÃ­ch cá»±c','ğŸ˜–':'tiÃªu cá»±c','ğŸ˜€':'tÃ­ch cá»±c',':((':'tiÃªu cá»±c','ğŸ˜¡':'tiÃªu cá»±c','ğŸ˜ ':'tiÃªu cá»±c','ğŸ˜’':'tiÃªu cá»±c','ğŸ™‚':'tÃ­ch cá»±c','ğŸ˜':'tiÃªu cá»±c','ğŸ˜':'tÃ­ch cá»±c','ğŸ˜„':'tÃ­ch cá»±c','ğŸ˜™':'tÃ­ch cá»±c','ğŸ˜¤':'tiÃªu cá»±c','ğŸ˜':'tÃ­ch cá»±c','ğŸ˜†':'tÃ­ch cá»±c','ğŸ’š':'tÃ­ch cá»±c','âœŒ':'tÃ­ch cá»±c','ğŸ’•':'tÃ­ch cá»±c','ğŸ˜':'tiÃªu cá»±c','ğŸ˜“':'tiÃªu cá»±c','ï¸ğŸ†—ï¸':'tÃ­ch cá»±c','ğŸ˜‰':'tÃ­ch cá»±c','ğŸ˜‚':'tÃ­ch cá»±c',':v':'tÃ­ch cá»±c','=))':'tÃ­ch cá»±c','ğŸ˜‹':'tÃ­ch cá»±c','ğŸ’“':'tÃ­ch cá»±c','ğŸ˜':'tiÃªu cá»±c',':3':'tÃ­ch cá»±c','ğŸ˜«':'tiÃªu cá»±c','ğŸ˜¥':'tiÃªu cá»±c','ğŸ˜ƒ':'tÃ­ch cá»±c','ğŸ˜¬':' ğŸ˜¬ ','ğŸ˜Œ':' ğŸ˜Œ ','ğŸ’›':'tÃ­ch cá»±c','ğŸ¤':'tÃ­ch cá»±c','ğŸˆ':'tÃ­ch cá»±c','ğŸ˜—':'tÃ­ch cá»±c','ğŸ¤”':'tiÃªu cá»±c','ğŸ˜‘':'tiÃªu cá»±c','ğŸ”¥':'tiÃªu cá»±c','ğŸ™':'tiÃªu cá»±c','ğŸ†—':'tÃ­ch cá»±c','ğŸ˜»':'tÃ­ch cá»±c','ğŸ’™':'tÃ­ch cá»±c','ğŸ’Ÿ':'tÃ­ch cá»±c','ğŸ˜š':'tÃ­ch cá»±c','âŒ':'tiÃªu cá»±c','ğŸ‘':'tÃ­ch cá»±c',';)':'tÃ­ch cá»±c','<3':'tÃ­ch cá»±c','ğŸŒ':'tÃ­ch cá»±c','ğŸŒ·':'tÃ­ch cá»±c','ğŸŒ¸':'tÃ­ch cá»±c','ğŸŒº':'tÃ­ch cá»±c','ğŸŒ¼':'tÃ­ch cá»±c','ğŸ“':'tÃ­ch cá»±c','ğŸ…':'tÃ­ch cá»±c','ğŸ¾':'tÃ­ch cá»±c','ğŸ‘‰':'tÃ­ch cá»±c','ğŸ’':'tÃ­ch cá»±c','ğŸ’':'tÃ­ch cá»±c','ğŸ’¥':'tÃ­ch cá»±c','ğŸ’ª':'tÃ­ch cá»±c','ğŸ’°':'tÃ­ch cá»±c','ğŸ˜‡':'tÃ­ch cá»±c','ğŸ˜›':'tÃ­ch cá»±c','ğŸ˜œ':'tÃ­ch cá»±c','ğŸ™ƒ':'tÃ­ch cá»±c','ğŸ¤‘':'tÃ­ch cá»±c','\U0001f92a':'tÃ­ch cá»±c','â˜¹':'tiÃªu cá»±c','ğŸ’€':'tiÃªu cá»±c','ğŸ˜”':'tiÃªu cá»±c','ğŸ˜§':'tiÃªu cá»±c','ğŸ˜©':'tiÃªu cá»±c','ğŸ˜°':'tiÃªu cá»±c','ğŸ˜³':'tiÃªu cá»±c','ğŸ˜µ':'tiÃªu cá»±c','ğŸ˜¶':'tiÃªu cá»±c','ğŸ™':'tiÃªu cá»±c',':))':'tÃ­ch cá»±c',':)':'tÃ­ch cá»±c','Ã´ kÃªi':' ok ','okie':' ok ',' o kÃª ':' ok ','okey':' ok ','Ã´kÃª':' ok ','oki':' ok ',' oke ':' ok ',' okay':' ok ','okÃª':' ok ',' tks ':' cÃ¡m Æ¡n ','thks':' cÃ¡m Æ¡n ','thanks':' cÃ¡m Æ¡n ','ths':' cÃ¡m Æ¡n ','thank':' cÃ¡m Æ¡n ','â­':'star ','*':'star ','ğŸŒŸ':'star ','ğŸ‰':'tÃ­ch cá»±c','kg ':' khÃ´ng ','not':' khÃ´ng ',' kg ':' khÃ´ng ','"k ':' khÃ´ng ',' kh ':' khÃ´ng ','kÃ´':' khÃ´ng ','hok':' khÃ´ng ',' kp ':' khÃ´ng pháº£i ',' kÃ´ ':' khÃ´ng ','"ko ':' khÃ´ng ',' ko ':' khÃ´ng ',' k ':' khÃ´ng ','khong':' khÃ´ng ',' hok ':' khÃ´ng ','he he':'tÃ­ch cá»±c','hehe':'tÃ­ch cá»±c','hihi':'tÃ­ch cá»±c','haha':'tÃ­ch cá»±c','hjhj':'tÃ­ch cá»±c',' lol ':'tiÃªu cá»±c',' cc ':'tiÃªu cá»±c','cute':' dá»… thÆ°Æ¡ng ','huhu':'tiÃªu cá»±c',' vs ':' vá»›i ','wa':' quÃ¡ ','wÃ¡':' quÃ¡','j':' gÃ¬ ','â€œ':' ',' sz ':' cá»¡ ','size':' cá»¡ ',' Ä‘x ':' Ä‘Æ°á»£c ','dk':' Ä‘Æ°á»£c ','dc':' Ä‘Æ°á»£c ','Ä‘k':' Ä‘Æ°á»£c ','Ä‘c':' Ä‘Æ°á»£c ','authentic':' chuáº©n chÃ­nh hÃ£ng ',' aut ':' chuáº©n chÃ­nh hÃ£ng ',' auth ':' chuáº©n chÃ­nh hÃ£ng ','thick':'tÃ­ch cá»±c','store':' cá»­a hÃ ng ','shop':' cá»­a hÃ ng ','sp':' sáº£n pháº©m ','gud':' tá»‘t ','god':' tá»‘t ','wel done':' tá»‘t ','good':' tá»‘t ','gÃºt':' tá»‘t ','sáº¥u':' xáº¥u ','gut':' tá»‘t ',' tot ':' tá»‘t ',' nice ':' tá»‘t ','perfect':'ráº¥t tá»‘t','bt':' bÃ¬nh thÆ°á»ng ','time':' thá»i gian ','qÃ¡':' quÃ¡ ',' ship ':' giao hÃ ng ',' m ':' mÃ¬nh ',' mik ':' mÃ¬nh ','ÃªÌ‰':'á»ƒ','product':'sáº£n pháº©m','quality':'cháº¥t lÆ°á»£ng','chat':' cháº¥t ','excelent':'hoÃ n háº£o','bad':'tá»‡','fresh':' tÆ°Æ¡i ','sad':' tá»‡ ','date':' háº¡n sá»­ dá»¥ng ','hsd':' háº¡n sá»­ dá»¥ng ','quickly':' nhanh ','quick':' nhanh ','fast':' nhanh ','delivery':' giao hÃ ng ',' sÃ­p ':' giao hÃ ng ','beautiful':' Ä‘áº¹p tuyá»‡t vá»i ',' tl ':' tráº£ lá»i ',' r ':' rá»“i ',' shopE ':' cá»­a hÃ ng ',' order ':' Ä‘áº·t hÃ ng ','cháº¥t lg':' cháº¥t lÆ°á»£ng ',' sd ':' sá»­ dá»¥ng ',' dt ':' Ä‘iá»‡n thoáº¡i ',' nt ':' nháº¯n tin ',' sÃ i ':' xÃ i ','bjo':' bao giá» ','thik':' thÃ­ch ',' sop ':' cá»­a hÃ ng ',' fb ':' facebook ',' face ':' facebook ',' very ':' ráº¥t ','quáº£ ng ':' quáº£ng  ','dep':' Ä‘áº¹p ',' xau ':' xáº¥u ','delicious':' ngon ','hÃ g':' hÃ ng ','qá»§a':' quáº£ ','iu':' yÃªu ','fake':' giáº£ máº¡o ','trl':'tráº£ lá»i','><':'tÃ­ch cá»±c',' por ':' tá»‡ ',' poor ':' tá»‡ ','ib':' nháº¯n tin ','rep':' tráº£ lá»i ','fback':' feedback ','fedback':' feedback '}
def clean_sentences(string):
    string = string.lower().replace("<br />", " ")
    for k, v in replace_list.items():
        string = string.replace(k, v)
    return re.sub(strip_special_chars, "", string.lower())


def get_sentence_indices(sentence, max_seq_length, _words_list):
    """
    HÃ m nÃ y dÃ¹ng Ä‘á»ƒ láº¥y index cho tá»«ng tá»«
    trong cÃ¢u (khÃ´ng cÃ³ dáº¥u cÃ¢u, cÃ³ thá»ƒ in hoa)
    Parameters
    ----------
    sentence lÃ  cÃ¢u cáº§n xá»­ lÃ½
    max_seq_length lÃ  giá»›i háº¡n sá»‘ tá»« tá»‘i Ä‘a trong cÃ¢u
    _words_list lÃ  báº£n sao local cá»§a words_list, Ä‘Æ°á»£c truyá»n vÃ o hÃ m
    """
    indices = np.zeros((max_seq_length), dtype='int32')

    # TÃ¡ch cÃ¢u thÃ nh tá»«ng tiáº¿ng
    words = [word.lower() for word in sentence.split()]

    # Láº¥y chá»‰ sá»‘ cá»§a UNK
    unk_idx = word2idx['UNK']

    for idx, word in enumerate(words):
        if idx < max_seq_length:
            if (word in _words_list):
                word_idx = word2idx[word]
            else:
                word_idx = word2idx['UNK']

            indices[idx] = word_idx
        else:
            break

    return indices


def text2ids(df, max_length, _word_list):
    """
    Biáº¿n Ä‘á»•i cÃ¡c text trong dataframe thÃ nh ma tráº­n index

    Parameters
    ----------
    df: DataFrame
        dataframe chá»©a cÃ¡c text cáº§n biáº¿n Ä‘á»•i
    max_length: int
        Ä‘á»™ dÃ i tá»‘i Ä‘a cá»§a má»™t text
    _word_list: numpy.array
        array chá»©a cÃ¡c tá»« trong word vectors

    Returns
    -------
    numpy.array
        len(df) x max_length contains indices of text
    """
    ids = np.zeros((len(df), max_length), dtype='int32')
    for idx, text in enumerate(tqdm(df['text'])):
        ids[idx, :] = get_sentence_indices(clean_sentences(text), max_length, _word_list)
    return ids

